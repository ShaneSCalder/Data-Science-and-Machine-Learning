{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crimes in Boston \n",
    "\n",
    "- Times, locations and descriptions of crimes\n",
    "- https://www.kaggle.com/AnalyzeBoston/crimes-in-boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare the Data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/crime.csv'\n",
    "\n",
    "\n",
    "crime_data = pd.read_csv(data_path, encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCIDENT_NUMBER</th>\n",
       "      <th>OFFENSE_CODE</th>\n",
       "      <th>OFFENSE_CODE_GROUP</th>\n",
       "      <th>OFFENSE_DESCRIPTION</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>REPORTING_AREA</th>\n",
       "      <th>SHOOTING</th>\n",
       "      <th>OCCURRED_ON_DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>UCR_PART</th>\n",
       "      <th>STREET</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I182070945</td>\n",
       "      <td>619</td>\n",
       "      <td>Larceny</td>\n",
       "      <td>LARCENY ALL OTHERS</td>\n",
       "      <td>D14</td>\n",
       "      <td>808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-02 13:00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>13</td>\n",
       "      <td>Part One</td>\n",
       "      <td>LINCOLN ST</td>\n",
       "      <td>42.357791</td>\n",
       "      <td>-71.139371</td>\n",
       "      <td>(42.35779134, -71.13937053)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I182070943</td>\n",
       "      <td>1402</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>VANDALISM</td>\n",
       "      <td>C11</td>\n",
       "      <td>347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-21 00:00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>Part Two</td>\n",
       "      <td>HECLA ST</td>\n",
       "      <td>42.306821</td>\n",
       "      <td>-71.060300</td>\n",
       "      <td>(42.30682138, -71.06030035)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I182070941</td>\n",
       "      <td>3410</td>\n",
       "      <td>Towed</td>\n",
       "      <td>TOWED MOTOR VEHICLE</td>\n",
       "      <td>D4</td>\n",
       "      <td>151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-03 19:27:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>Monday</td>\n",
       "      <td>19</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>CAZENOVE ST</td>\n",
       "      <td>42.346589</td>\n",
       "      <td>-71.072429</td>\n",
       "      <td>(42.34658879, -71.07242943)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I182070940</td>\n",
       "      <td>3114</td>\n",
       "      <td>Investigate Property</td>\n",
       "      <td>INVESTIGATE PROPERTY</td>\n",
       "      <td>D4</td>\n",
       "      <td>272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-03 21:16:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>Monday</td>\n",
       "      <td>21</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>NEWCOMB ST</td>\n",
       "      <td>42.334182</td>\n",
       "      <td>-71.078664</td>\n",
       "      <td>(42.33418175, -71.07866441)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I182070938</td>\n",
       "      <td>3114</td>\n",
       "      <td>Investigate Property</td>\n",
       "      <td>INVESTIGATE PROPERTY</td>\n",
       "      <td>B3</td>\n",
       "      <td>421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-03 21:05:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>Monday</td>\n",
       "      <td>21</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>DELHI ST</td>\n",
       "      <td>42.275365</td>\n",
       "      <td>-71.090361</td>\n",
       "      <td>(42.27536542, -71.09036101)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  INCIDENT_NUMBER  OFFENSE_CODE    OFFENSE_CODE_GROUP   OFFENSE_DESCRIPTION  \\\n",
       "0      I182070945           619               Larceny    LARCENY ALL OTHERS   \n",
       "1      I182070943          1402             Vandalism             VANDALISM   \n",
       "2      I182070941          3410                 Towed   TOWED MOTOR VEHICLE   \n",
       "3      I182070940          3114  Investigate Property  INVESTIGATE PROPERTY   \n",
       "4      I182070938          3114  Investigate Property  INVESTIGATE PROPERTY   \n",
       "\n",
       "  DISTRICT REPORTING_AREA SHOOTING     OCCURRED_ON_DATE  YEAR  MONTH  \\\n",
       "0      D14            808      NaN  2018-09-02 13:00:00  2018      9   \n",
       "1      C11            347      NaN  2018-08-21 00:00:00  2018      8   \n",
       "2       D4            151      NaN  2018-09-03 19:27:00  2018      9   \n",
       "3       D4            272      NaN  2018-09-03 21:16:00  2018      9   \n",
       "4       B3            421      NaN  2018-09-03 21:05:00  2018      9   \n",
       "\n",
       "  DAY_OF_WEEK  HOUR    UCR_PART       STREET        Lat       Long  \\\n",
       "0      Sunday    13    Part One   LINCOLN ST  42.357791 -71.139371   \n",
       "1     Tuesday     0    Part Two     HECLA ST  42.306821 -71.060300   \n",
       "2      Monday    19  Part Three  CAZENOVE ST  42.346589 -71.072429   \n",
       "3      Monday    21  Part Three   NEWCOMB ST  42.334182 -71.078664   \n",
       "4      Monday    21  Part Three     DELHI ST  42.275365 -71.090361   \n",
       "\n",
       "                      Location  \n",
       "0  (42.35779134, -71.13937053)  \n",
       "1  (42.30682138, -71.06030035)  \n",
       "2  (42.34658879, -71.07242943)  \n",
       "3  (42.33418175, -71.07866441)  \n",
       "4  (42.27536542, -71.09036101)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319073, 17)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_crime_data = crime_data[['DISTRICT',\n",
    "                'OFFENSE_CODE',\n",
    "                'OCCURRED_ON_DATE',\n",
    "                'HOUR',\n",
    "                'DAY_OF_WEEK']].copy()\n",
    "new_crime_data.head()\n",
    "\n",
    "dummy_fields = ['DISTRICT', 'OFFENSE_CODE', 'HOUR', 'DAY_OF_WEEK']\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(new_crime_data[each], prefix=each, drop_first=False)\n",
    "    new_crime_data = pd.concat([new_crime_data, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into training, testing, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for approximately 10000 time stamps   \n",
    "test_data = new_crime_data[-10000*24:]\n",
    "\n",
    "# Now remove the test data from the data set \n",
    "test_data = test_data[:-10000*24]\n",
    "\n",
    "# Separate the data into features and targets\n",
    "target_fields = ['DISTRICT', 'OFFENSE_CODE', 'DAY_OF_WEEK']\n",
    "features, targets = new_crime_data.drop(target_fields, axis=1), new_crime_data[target_fields]\n",
    "test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out the last 100000 timestamps or the remaining data as a validation set\n",
    "train_features, train_targets = features[:-200000*24], targets[:-200000*24]\n",
    "val_features, val_targets = features[-200000*24:], targets[-200000*24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, \n",
    "                                       (self.input_nodes, self.hidden_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                       (self.hidden_nodes, self.output_nodes))\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        #### TODO: Set self.activation_function to your implemented sigmoid function ####\n",
    "        #\n",
    "        # Note: in Python, you can define a function with a lambda expression,\n",
    "        # as shown below.\n",
    "        self.activation_function = lambda x : (1 / (1 + np.exp(-x)) )  # Replace 0 with your sigmoid calculation.\n",
    "        \n",
    "        ### If the lambda code above is not something you're familiar with,\n",
    "        # You can uncomment out the following three lines and put your \n",
    "        # implementation there instead.\n",
    "        #\n",
    "        #def sigmoid(x):\n",
    "        #    return 0  # Replace 0 with your sigmoid calculation here\n",
    "        #self.activation_function = sigmoid\n",
    "        \n",
    "        #def sigmoid(x):\n",
    "        #    return 1 / (1 + np.exp(-x))\n",
    "        #self.activation_function = sigmoid\n",
    "        \n",
    "    \n",
    "    def train(self, features, targets):\n",
    "        ''' Train the network on batch of features and targets. \n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            \n",
    "            features: 2D array, each row is one data record, each column is a feature\n",
    "            targets: 1D array of target values\n",
    "        \n",
    "        '''\n",
    "        n_records = np.array(features).shape[0]\n",
    "        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "        for X, y in zip(features, targets):\n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "            # TODO: Hidden layer - Replace these values with your calculations.\n",
    "            hidden_inputs = np.dot(X, self.weights_input_to_hidden) # signals into hidden layer\n",
    "            hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n",
    "\n",
    "            # TODO: Output layer - Replace these values with your calculations.\n",
    "            final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n",
    "            final_outputs = final_inputs # signals from final output layer\n",
    "            \n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "            # TODO: Output error - Replace this value with your calculations.\n",
    "            error = y - final_outputs # Output layer error is the difference between desired target and actual output.\n",
    "            \n",
    "            # TODO: Calculate the hidden layer's contribution to the error\n",
    "            hidden_error = np.dot(error, self.weights_hidden_to_output.T) #error * final_outputs * (1 - Final_outputs) \n",
    "            \n",
    "            # TODO: Backpropagated error terms - Replace these values with your calculations.\n",
    "            output_error_term = error * 1 # output_error_term * final_outputs * (1 - final_outputs) error * 1\n",
    "            hidden_error_term = hidden_error * hidden_outputs * (1 - hidden_outputs) \n",
    "\n",
    "            # Weight step (input to hidden)\n",
    "            delta_weights_i_h += hidden_error_term * X[:, None]\n",
    "            # Weight step (hidden to output)\n",
    "            delta_weights_h_o += output_error_term * hidden_outputs[:, None] #output_error_term *\n",
    "\n",
    "        # TODO: Update the weights - Replace these values with your calculations.\n",
    "        self.weights_hidden_to_output += self.lr * delta_weights_h_o/n_records \n",
    "        self.weights_input_to_hidden += self.lr * delta_weights_i_h/n_records \n",
    "            \n",
    " \n",
    "    def run(self, features):\n",
    "        ''' Run a forward pass through the network with input features \n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            features: 1D array of feature values\n",
    "        '''\n",
    "        \n",
    "        #### Implement the forward pass here ####\n",
    "        # TODO: Hidden layer - replace these values with the appropriate calculations.\n",
    "        hidden_inputs = np.dot(features, self.weights_input_to_hidden) # signals into hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n",
    "        \n",
    "        # TODO: Output layer - Replace these values with the appropriate calculations.\n",
    "        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n",
    "        final_outputs = final_inputs # signals from final output layer \n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.011s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "inputs = np.array([[0.5, -0.2, 0.1]])\n",
    "targets = np.array([[0.4]])\n",
    "test_w_i_h = np.array([[0.1, -0.2],\n",
    "                       [0.4, 0.5],\n",
    "                       [-0.3, 0.2]])\n",
    "test_w_h_o = np.array([[0.3],\n",
    "                       [-0.1]])\n",
    "\n",
    "class TestMethods(unittest.TestCase):\n",
    "    \n",
    "    ##########\n",
    "    # Unit tests for data loading\n",
    "    ##########\n",
    "    \n",
    "    def test_data_path(self):\n",
    "        # Test that file path to dataset has been unaltered\n",
    "        self.assertTrue(data_path.lower() == 'data/crime.csv')\n",
    "        \n",
    "    def test_data_loaded(self):\n",
    "        # Test that data frame loaded\n",
    "        self.assertTrue(isinstance(new_crime_data, pd.DataFrame))\n",
    "    \n",
    "    ##########\n",
    "    # Unit tests for network functionality\n",
    "    ##########\n",
    "\n",
    "    def test_activation(self):\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        # Test that the activation function is a sigmoid\n",
    "        self.assertTrue(np.all(network.activation_function(0.5) == 1/(1+np.exp(-0.5))))\n",
    "\n",
    "    def test_train(self):\n",
    "        # Test that weights are updated correctly on training\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "        \n",
    "        network.train(inputs, targets)\n",
    "        self.assertTrue(np.allclose(network.weights_hidden_to_output, \n",
    "                                    np.array([[ 0.37275328], \n",
    "                                              [-0.03172939]])))\n",
    "        self.assertTrue(np.allclose(network.weights_input_to_hidden,\n",
    "                                    np.array([[ 0.10562014, -0.20185996], \n",
    "                                              [0.39775194, 0.50074398], \n",
    "                                              [-0.29887597, 0.19962801]])))\n",
    "\n",
    "    def test_run(self):\n",
    "        # Test correctness of run method\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "\n",
    "        self.assertTrue(np.allclose(network.run(inputs), 0.09998924))\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromModule(TestMethods())\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-47fbbed69adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Go through a random batch of 256 records from the training data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DISTRICT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Set the hyperparameters here ###\n",
    "iterations = 1000\n",
    "learning_rate = .15\n",
    "hidden_nodes = 128\n",
    "output_nodes = 1\n",
    "\n",
    "N_i = train_features.shape[1]\n",
    "network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "losses = {'train':[], 'validation':[]}\n",
    "for ii in range(iterations):\n",
    "    # Go through a random batch of 256 records from the training data set\n",
    "    batch = np.random.choice(train_features.index, size=256)\n",
    "    X, y = train_features.ix[batch].values, train_targets.ix[batch]['DISTRICT']\n",
    "                             \n",
    "    network.train(X, y)\n",
    "    \n",
    "    # Printing out the training progress\n",
    "    train_loss = MSE(network.run(train_features).T, train_targets['DISTRICT'].values)\n",
    "    val_loss = MSE(network.run(val_features).T, val_targets['DISTRICT'].values)\n",
    "    sys.stdout.write(\"\\rProgress: {:2.1f}\".format(100 * ii/float(iterations)) \\\n",
    "                     + \"% ... Training loss: \" + str(train_loss)[:5] \\\n",
    "                     + \" ... Validation loss: \" + str(val_loss)[:5])\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
